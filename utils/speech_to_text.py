
import whisper
import os
from deep_translator import GoogleTranslator  # ‡πÉ‡∏ä‡πâ deep_translator ‡πÅ‡∏ó‡∏ô

def transcribe_audio(audio_path, output_dir="static/subtitles"):
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Whisper
        model = whisper.load_model("small")  # ‡∏´‡∏£‡∏∑‡∏≠ "base" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
        print("Model loaded successfully.")
        
        # ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
        result = model.transcribe(audio_path)  # ‡πÑ‡∏°‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î language, Whisper ‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        segments = result["segments"]
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå SRT ‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        basename = os.path.splitext(os.path.basename(audio_path))[0]
        srt_path = os.path.join(output_dir, f"{basename}.srt")

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤
        detected_language = result["language"]  # ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà Whisper ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
        print(f"Detected language: {detected_language}")

        with open(srt_path, "w", encoding="utf-8") as f:
            for i, seg in enumerate(segments, 1):
                start = whisper.utils.format_timestamp(seg["start"])
                end = whisper.utils.format_timestamp(seg["end"])
                text_original = seg["text"].strip()  # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á
                
                # ‡πÅ‡∏õ‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
                text_translated = GoogleTranslator(source=detected_language, target='en').translate(text_original)
                f.write(f"{i}\n{start} --> {end}\n{text_translated}\n\n")
        
        print(f"SRT file saved at: {srt_path}")
        return srt_path
    except Exception as e:
        print(f"Error during transcription or translation: {e}")
        return None


# from faster_whisper import WhisperModel
# import os
# from deep_translator import GoogleTranslator

# def transcribe_audio(audio_path, output_dir="static/subtitles"):
#     os.makedirs(output_dir, exist_ok=True)

#     try:
#         print("üîç Transcribing audio...")
#         model = WhisperModel("small", compute_type="int8", device="cpu")
#         segments, info = model.transcribe(audio_path)
        
#         detected_language = info.language
#         print(f"üåê Detected language: {detected_language}")

#         basename = os.path.splitext(os.path.basename(audio_path))[0]
#         srt_path = os.path.join(output_dir, f"{basename}.srt")

#         with open(srt_path, "w", encoding="utf-8") as f:
#             for i, seg in enumerate(segments, 1):
#                 start = format_timestamp(seg.start)
#                 end = format_timestamp(seg.end)
#                 text = seg.text.strip()
                
#                 # ‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
#                 text_translated = GoogleTranslator(source=detected_language, target='en').translate(text)
#                 f.write(f"{i}\n{start} --> {end}\n{text_translated}\n\n")

#         print(f"‚úÖ SRT file saved at: {srt_path}")
#         return srt_path

#     except Exception as e:
#         print(f"‚ùå Error during transcription/translation: {e}")
#         return None


# def format_timestamp(seconds):
#     h = int(seconds // 3600)
#     m = int((seconds % 3600) // 60)
#     s = int(seconds % 60)
#     ms = int((seconds - int(seconds)) * 1000)
#     return f"{h:02}:{m:02}:{s:02}.{ms:03}"

